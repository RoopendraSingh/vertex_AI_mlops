name: Data ingestion
inputs:
- {name: bucket_name, type: String}
- {name: notebook_path, type: String}
outputs:
- {name: smetrics, type: Metrics}
- {name: gcsFile, type: String}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-api-python-client' 'gcsfs' 'google-cloud' 'google-cloud-storage' 'kfp==1.8.6' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def data_ingestion(bucket_name: str,notebook_path:str,smetrics: Output[Metrics])-> NamedTuple("Outputs", [("gcsFile", str)]):
          from google.cloud import storage

          """This module returns the filepath"""
          def list_blobs_with_prefix(bucket_name:str, delimiter=None):
              """Gives the last updated file path
                 Inputs: GCS bucket name
                 Outputs: train file path
              """
              storage_client = storage.Client()
              blobs = storage_client.list_blobs(bucket_name, delimiter=delimiter)
              dict_blob = {}
              for blob in blobs:
                  dict_blob[blob.name] = blob.updated
              blob_update_list = list(dict_blob.values())
              sorted_dict_blob = {k: v for k, v in sorted(dict_blob.items(),
                                                          key=lambda item: item[1], reverse = True)}
              get_latest_file_name = list(sorted_dict_blob.keys())[0]
              return get_latest_file_name
          file_name = list_blobs_with_prefix(bucket_name,delimiter=None)
          get_gcs_File = f'gs://{bucket_name}/'+file_name
          print("Data DownLoaded Sucessfully")
          print(get_gcs_File)
          if notebook_path == 'NA':
              return(get_gcs_File,)
          else:
              smetrics.log_metric("path to code:",notebook_path)
              return(get_gcs_File,)

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - data_ingestion
