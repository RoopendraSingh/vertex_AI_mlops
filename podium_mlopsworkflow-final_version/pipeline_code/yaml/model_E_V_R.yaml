name: Model E V R
description: This function is for getting predictions and F1-score from new model
  and then validating the model by comparing
inputs:
- {name: model, type: Model}
- {name: MODEL_BUCKET_NAME, type: String}
- {name: BUCKET_NAME_THRESHOLD, type: String}
- {name: BUCKET_NAME_TESTING, type: String}
outputs:
- {name: metrics, type: Metrics}
- {name: check, type: Boolean}
- {name: new_model_path, type: String}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'sklearn' 'pandas' 'google-api-python-client' 'gcsfs' 'google-cloud' 'google-cloud-storage' 'argparse' 'google-cloud-aiplatform==1.1.1' 'xgboost' 'numpyencoder' 'kfp==1.8.6' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
      \ import *\n\ndef model_E_V_R(model:Input[Model],MODEL_BUCKET_NAME: str, BUCKET_NAME_THRESHOLD:\
      \ str, BUCKET_NAME_TESTING: str,\n                metrics:Output[Metrics])->\
      \ NamedTuple(\"Outputs\", [(\"check\", bool),(\"new_model_path\",str)]):\n \
      \   \"\"\"\n       This function is for getting predictions and F1-score from\
      \ new model and then validating the model by comparing\n       it to previously\
      \ validated model and then saving model metadata to Vertex AI Metadata service.\n\
      \       Inputs: model                  - recently trained model\n          \
      \     MODEL_BUCKET_NAME      - bucket where recently trained model is saved\
      \ as model.bst\n               BUCKET_NAME_THRESHOLD  - bucket containing F1\
      \ score of deployed model\n               BUCKET_NAME_TESTING    - path to latest\
      \ test data which is in a gcs bucket\n       Outputs: flag            -  deployment\
      \ decision for the model\n                new_model_path  -  path to current\
      \ model saved in GCS bucket\n    \"\"\"\n    import argparse\n    import numpy\
      \ as np\n    import pandas as pd\n    import os\n    from sklearn.metrics import\
      \ f1_score\n    from google.cloud import aiplatform\n    import json\n    from\
      \ google.cloud import storage\n    import gcsfs\n    from numpyencoder import\
      \ NumpyEncoder\n    from xgboost import XGBClassifier\n    #Getting model path\n\
      \    model_path =model.uri\n    #Getting Test Data\n    new_test_data = pd.read_csv(BUCKET_NAME_TESTING)\n\
      \    x_test_data=new_test_data.drop('class',axis=1)\n    y_test_data=new_test_data['class']\n\
      \    #Getting trained model\n    storage_client = storage.Client()\n    bucket\
      \ = storage_client.get_bucket(model_path.split(\"/\")[2])\n    blob_name = model_path.split('/')[3:]\n\
      \    blob_name = \"/\".join(blob_name)+'.bst'\n    blob = bucket.blob(blob_name)\n\
      \    model_name = model_path.split(\"/\")[-1]\n    model_name = model_name+'.bst'\n\
      \    blob.download_to_filename(model_name)\n    model3 = XGBClassifier()\n \
      \   model3.load_model(model_name)\n    #Getting the predictions\n    y_pred\
      \ = model3.predict(x_test_data)\n    model_metrics=f1_score(y_test_data,y_pred,average=None)\n\
      \    #Saving model metrics in a Dictionary\n    model_metrics_avg=(model_metrics[0]+model_metrics[1])/2\n\
      \    model_metric_dict = {}\n    model_metric_dict['F1-score'] = model_metrics_avg\n\
      \    #Getting object names from BUCKET_NAME_THRESHOLD\n    storage_client =\
      \ storage.Client()\n    bucket = storage_client.get_bucket(BUCKET_NAME_THRESHOLD)\n\
      \    blobs = storage_client.list_blobs(BUCKET_NAME_THRESHOLD)\n    bucket_object_names=''\n\
      \    #initiallizing flag variable which will we used to identify which model\
      \ to deploy\n    flag = False\n    for blob in blobs:\n        bucket_object_names=bucket_object_names+'/'+blob.name\n\
      \n    #Checking if BUCKET_NAME_THRESHOLD is empty or not\n    #If it's empty\
      \ then pipeline is running for first time\n    if bucket_object_names=='':\n\
      \        #Checking if F1 score is greater than 0.6\n        if model_metrics_avg>0.6:\n\
      \            flag = True\n            json_file_name = \"model.json\"\n    \
      \        #Saving metric Dictionary in json file\n            with open(json_file_name,\
      \ 'w') as file:\n                json.dump(model_metric_dict, file, cls=NumpyEncoder)\n\
      \            #Saving json file to GCS bucket\n            storage_client = storage.Client()\n\
      \            bucket = storage_client.bucket(BUCKET_NAME_THRESHOLD)\n       \
      \     bucket.blob(json_file_name).upload_from_filename(json_file_name)\n   \
      \         #Saving model to GCS bucket \n            storage_client = storage.Client()\n\
      \            bucket = storage_client.bucket(MODEL_BUCKET_NAME)\n           \
      \ bucket.blob('model.bst').upload_from_filename(model_name)\n            new_model_path\
      \ = 'gs://'+MODEL_BUCKET_NAME+'/model.bst'\n            #Saving metadata in\
      \ Vertex AI metadata service\n            metrics.log_metric(\"new-model-F1-Score-avg\"\
      ,model_metrics_avg)\n            metrics.log_metric(\"deployed-model-F1-Score-avg\"\
      ,\"no model deployed yet\")\n            #metrics.log_metric(\"newly-uploaded-model\"\
      ,model_name)\n            metrics.log_metric(\"deployment-status\",\"true\"\
      )\n            metrics.log_metric(\"framework\", \"XGB Classifier\")\n     \
      \       metrics.log_metric(\"dataset_size\", len(new_test_data))\n        else:\n\
      \            flag = False\n            #Saving model to GCS bucket \n      \
      \      storage_client = storage.Client()\n            bucket = storage_client.bucket(MODEL_BUCKET_NAME)\n\
      \            bucket.blob('model.bst').upload_from_filename(model_name)\n   \
      \         new_model_path = 'gs://'+MODEL_BUCKET_NAME+'/model.bst'\n        \
      \    #Saving metadata in Vertex AI metadata service\n            metrics.log_metric(\"\
      new-model-F1-Score-avg\",model_metrics_avg)\n            metrics.log_metric(\"\
      deployed-model-F1-Score-avg\",\"no model deployed yet\")\n            #metrics.log_metric(\"\
      newly-uploaded-model\",model_name)\n            metrics.log_metric(\"deployment-status\"\
      ,\"false\")\n            metrics.log_metric(\"framework\", \"XGB Classifier\"\
      )\n            metrics.log_metric(\"dataset_size\", len(new_test_data))\n\n\
      \    else:\n        #Getting model.json file from 'BUCKET_NAME_THRESHOLD' bucket\n\
      \        storage_client = storage.Client()\n        bucket = storage_client.get_bucket(BUCKET_NAME_THRESHOLD)\n\
      \        blob = bucket.blob('model.json')\n        # Download the contents of\
      \ the blob as a string and then parse it using json.loads() method\n       \
      \ data = json.loads(blob.download_as_string(client=None))\n        print(data)\n\
      \        print(type(data))\n        print(list(data.values())[0])\n        deployed_model_threshold\
      \ = list(data.values())[0]\n\n        #Checking if F1-score of new model is\
      \ greater or smaller than Deployed model's F1-score  \n        if  model_metrics_avg\
      \ < deployed_model_threshold:\n            #F1-score is smaller so new_model\
      \ will not be deployed\n            flag = False\n            #Saving Validated\
      \ model to GCS bucket \n            storage_client = storage.Client()\n    \
      \        bucket = storage_client.bucket(MODEL_BUCKET_NAME)\n            bucket.blob('model.bst').upload_from_filename(model_name)\n\
      \            new_model_path = 'gs://'+MODEL_BUCKET_NAME+'/model.bst'\n     \
      \       #Saving metadata in Vertex AI metadata service\n             #new_model_path\
      \ = 'gs://'+MODEL_BUCKET_NAME+'/model.bst'\n            metrics.log_metric(\"\
      new-model-F1-Score-avg\",model_metrics_avg)\n            metrics.log_metric(\"\
      deployed-model-F1-Score-avg\",deployed_model_threshold)\n            #metrics.log_metric(\"\
      newly-uploaded-model\",model_name)\n            metrics.log_metric(\"deployment-status\"\
      ,\"false\")\n            metrics.log_metric(\"framework\", \"XGB Classifier\"\
      )\n            metrics.log_metric(\"dataset_size\", len(new_test_data))\n\n\
      \        else:\n            #F1-score is greater so new_model will be deployed\n\
      \            flag = True\n            json_Filename = \"model.json\"\n     \
      \       #Updating metric json file with new F1-score\n            with open(json_Filename,\
      \ 'w') as file:  \n                json.dump(model_metric_dict, file, cls=NumpyEncoder)\n\
      \            bucket.blob(json_Filename).upload_from_filename(json_Filename)\n\
      \            #Saving Validated model to GCS bucket \n            storage_client\
      \ = storage.Client()\n            bucket = storage_client.bucket(MODEL_BUCKET_NAME)\n\
      \            bucket.blob('model.bst').upload_from_filename(model_name)\n   \
      \         new_model_path = 'gs://'+MODEL_BUCKET_NAME+'/model.bst'\n        \
      \    #Saving metadata in Vertex AI metadata service\n            metrics.log_metric(\"\
      new-model-F1-Score-avg\",model_metrics_avg)\n            metrics.log_metric(\"\
      deployed-model-F1-Score-avg\",deployed_model_threshold)\n            #metrics.log_metric(\"\
      newly-uploaded-model\",model_name)\n            metrics.log_metric(\"deployment-status\"\
      ,\"true\")\n            metrics.log_metric(\"framework\", \"XGB Classifier\"\
      )\n            metrics.log_metric(\"dataset_size\", len(new_test_data))\n\n\
      \    return (flag,new_model_path,)\n\n"
    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - model_E_V_R
